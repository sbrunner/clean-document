#!/usr/bin/env python3

import argparse
import glob
import math
import os.path
import random
import subprocess
import sys
from typing import List

import cv2
import keras.models
import numpy as np
import tensorflow as tf
import yaml
from keras.layers import Conv2D, Conv2DTranspose, Dropout, Input, MaxPooling2D, UpSampling2D, concatenate
from keras.models import Model

# keras==2.3.1 max 2.5.0
# https://faroit.com/keras-docs/2.0.5/
# install python3-tk
NUMBER_OF_IMAGES = 5
IMAGE_DIMENSION = 256


def data_augmentation_image(image, image_dimension):
    results = []

    # to yuv
    image = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)

    # split the image into regular IMAGE_DIMENSIONxIMAGE_DIMENSION images
    nb_x = math.ceil(image.shape[0] / image_dimension)
    nb_y = math.ceil(image.shape[1] / image_dimension)
    slide_x = (image.shape[0] - image_dimension) / (nb_x - 1)
    slide_y = (image.shape[1] - image_dimension) / (nb_y - 1)
    for x in range(nb_x):
        for y in range(nb_y):
            x0 = round(x * slide_x)
            y0 = round(y * slide_y)
            if x0 + image_dimension > image.shape[0]:
                print(nb_x, x, slide_x)
                print(image.shape, x0 + image_dimension, y0 + image_dimension)
            if y0 + image_dimension > image.shape[1]:
                print(nb_y, y, slide_y)
                print(image.shape, x0 + image_dimension, y0 + image_dimension)
            cropped = image[x0 : x0 + image_dimension, y0 : y0 + image_dimension]

            f"-{x}-{y}-"
            # base = '-'
            # cropped = image

            results += [cropped]
            assert len(results[-1].shape) == 3
            # rotate 180
            results += [cv2.rotate(cropped, cv2.ROTATE_180)]
            assert len(results[-1].shape) == 3
            results += [np.fliplr(cropped)]
            assert len(results[-1].shape) == 3
            # flip up down
            results += [np.flipud(cropped)]

            results += [np.flip(cropped)]
            assert len(results[-1].shape) == 3

    #    scale = random.uniform(0.5, 0.9)
    #    # scale = 0.8
    #    image = cv2.resize(image, (0, 0), fx=scale, fy=scale)
    #
    #    nb_x = math.ceil(image.shape[0] / image_dimension)
    #    nb_y = math.ceil(image.shape[1] / image_dimension)
    #    slide_x = (image.shape[0] - image_dimension) / (nb_x - 1) if nb_x > 1 else 0
    #    slide_y = (image.shape[1] - image_dimension) / (nb_y - 1) if nb_y > 1 else 0
    #    for x in range(nb_x):
    #        for y in range(nb_y):
    #            x0 = round(x * slide_x)
    #            y0 = round(y * slide_y)
    #            if x0 + image_dimension > image.shape[0]:
    #                print(nb_x, x, slide_x)
    #                print(image.shape, x0 + image_dimension, y0 + image_dimension)
    #            if y0 + image_dimension > image.shape[1]:
    #                print(nb_y, y, slide_y)
    #                print(image.shape, x0 + image_dimension, y0 + image_dimension)
    #            assert len(image.shape) == 3
    #            cropped = image[x0 : x0 + image_dimension, y0 : y0 + image_dimension]
    #
    #            results += [cropped]
    #            assert len(results[-1].shape) == 3
    #    print(len(results))
    return results


from keras.layers import Conv2D, Conv2DTranspose, Input, MaxPooling2D
from keras.models import Model


def model():
    input_ = Input(shape=(None, None, 3))

    # Encoder
    x = Conv2D(32, (3, 3), activation="relu", padding="same")(input_)
    x = MaxPooling2D((2, 2), padding="same")(x)
    x = Conv2D(32, (3, 3), activation="relu", padding="same")(x)
    x = MaxPooling2D((2, 2), padding="same")(x)

    # Decoder
    x = Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
    x = Conv2DTranspose(32, (3, 3), strides=2, activation="relu", padding="same")(x)
    x = Conv2D(3, (3, 3), activation="sigmoid", padding="same")(x)

    # Autoencoder
    autoencoder = Model(input_, x)
    autoencoder.compile(optimizer="adam", loss="binary_crossentropy")
    return autoencoder


MODELS = {
    f"denoise_{IMAGE_DIMENSION}": model,
}


dirty_image_file_name = random.choice(glob.glob("data/dirty/*.png"))
dirty_image = cv2.imread(dirty_image_file_name)

image_gray = cv2.cvtColor(dirty_image, cv2.COLOR_BGR2GRAY)
# add black band at the image bottom
image_gray = np.vstack((image_gray, np.zeros((50, image_gray.shape[1]))))

image_treshold = image_gray > 200
image_treshold = image_treshold.astype(np.uint8) * 255
# dilate (denoise)
image_treshold = cv2.dilate(image_treshold, np.ones((10, 10), np.uint8), iterations=1)
# erode
image_treshold = cv2.erode(image_treshold, np.ones((50, 50), np.uint8), iterations=1)
# remove the black band
image_treshold = image_treshold[:-50, :]
dirty_image[image_treshold < 127] = [255, 255, 255]


# Generator that returns the images
class Images:
    def __init__(self, filenames: List[str], length):
        self.filenames = filenames
        self.length = length

    def __call__(self):
        global dirty_image
        for filename in self.filenames:
            image = cv2.imread(filename)
            if image.shape[0] < image.shape[1]:
                image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
            width = max(image.shape[0], dirty_image.shape[0])
            height = max(image.shape[1], dirty_image.shape[1])
            if width != image.shape[0]:
                # Add white band at the right
                image = np.vstack(
                    (image, np.ones((width - image.shape[0], image.shape[1], 3), dtype=np.uint8) * 255)
                )
            if height != image.shape[1]:
                # Add white band at the bottom
                image = np.hstack(
                    (image, np.ones((image.shape[0], height - image.shape[1], 3), dtype=np.uint8) * 255)
                )
            current_dirty_image = dirty_image.copy()
            print(current_dirty_image.shape)
            if width != current_dirty_image.shape[0]:
                # Add black band at the right
                current_dirty_image = np.vstack(
                    (
                        current_dirty_image,
                        np.zeros(
                            (width - current_dirty_image.shape[0], current_dirty_image.shape[1], 3),
                            dtype=np.uint8,
                        ),
                    )
                )
            if height != current_dirty_image.shape[1]:
                # Add black band at the bottom
                current_dirty_image = np.hstack(
                    (
                        current_dirty_image,
                        np.zeros(
                            (current_dirty_image.shape[0], height - current_dirty_image.shape[1], 3),
                            dtype=np.uint8,
                        ),
                    )
                )

            current_dirty_images = data_augmentation_image(current_dirty_image, IMAGE_DIMENSION)
            images = data_augmentation_image(image, IMAGE_DIMENSION)
            for current_dirty_image, image in zip(current_dirty_images, images):
                current_dirty_image = np.expand_dims(current_dirty_image, axis=0)
                image = np.expand_dims(image, axis=0)
                yield current_dirty_image, image

    def __len__(self):
        return self.length


def train_many(model_name: str, filenames: List[str], test: List[str], gen_images: bool) -> None:
    if os.path.exists(f"results/{model_name}.keras"):
        model = keras.models.load_model(f"results/{model_name}.keras")
    else:
        model = MODELS[model_name]()
    if not os.path.exists(f"results/{model_name}.summary"):
        with open(f"results/{model_name}.summary", "w", encoding="utf-8") as summary_file:
            model.summary(print_fn=lambda x: summary_file.write(x + "\n"))

    # create a tf.data.Dataset.from_generator that returns to numpy array od shape (255, 255, 3
    # train = tf.data.Dataset.from_generator(
    #     Images(filenames),
    #     output_signature=(
    #         tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
    #         tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
    #     ),
    # )

    nb = 0
    for filename in filenames:
        image = cv2.imread(filename)
        if image.shape[0] < image.shape[1]:
            image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
        width = max(image.shape[0], dirty_image.shape[0])
        height = max(image.shape[1], dirty_image.shape[1])
        nb_x = math.ceil(width / IMAGE_DIMENSION)
        nb_y = math.ceil(height / IMAGE_DIMENSION)
        nb += nb_x * nb_y * 5

    nb_test = 0
    for filename in test:
        image = cv2.imread(filename)
        if image.shape[0] < image.shape[1]:
            image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)
        width = max(image.shape[0], dirty_image.shape[0])
        height = max(image.shape[1], dirty_image.shape[1])
        nb_x = math.ceil(width / IMAGE_DIMENSION)
        nb_y = math.ceil(height / IMAGE_DIMENSION)
        nb_test += nb_x * nb_y * 5

    for image in Images(filenames)():
        pass

    # x = tf.data.Dataset.from_generator(gen_x, output_types=(tf.float32, tf.float32))
    # y = tf.data.Dataset.from_generator(gen_y, output_types=(tf.float32, tf.float32))

    if gen_images:
        # Get the first image
        for nb, (sample_image, segmentation) in enumerate(Images(filenames)()):
            # save the images
            cv2.imwrite(f"results/{model_name}-noisy-{nb}.png", sample_image.numpy().astype(np.uint8)[0])
            cv2.imwrite(f"results/{model_name}-clean-{nb}.png", segmentation.numpy().astype(np.uint8)[0])
            return

    # val = tf.data.Dataset.from_generator(
    #     Images(test),
    #     output_signature=(
    #         tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
    #         tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
    #     ),
    # )
    # val = tf.data.Dataset.from_generator(Images(test), output_types=(tf.float32, tf.float32))

    try:
        if os.path.exists(f"results/{model_name}-history.yaml"):
            with open(f"results/{model_name}-history.yaml", encoding="utf-8") as history_file:
                history = yaml.load(history_file.read(), Loader=yaml.SafeLoader)
        else:
            history = {
                "loss": [],
                "val_loss": [],
            }
        print("Start fit")
        hist = model.fit(
            Images(filenames, nb)(),
            steps_per_epoch=nb,
            validation_data=Images(test, nb_test),
            # batch_size=100,
        )
        print("End fit")
        history.setdefault("loss", []).append(hist.history["loss"])
        history.setdefault("val_loss", []).append(hist.history["val_loss"])

        plt.plot(history["loss"])
        plt.plot(history["val_loss"])
        plt.title("Model loss")
        plt.ylabel("Loss")
        plt.legend(["Train", "Test"], loc="upper left")
        # Save plot to file
        plt.savefig(f"results/{model_name}.png")

        # Save the model
        model.save(f"results/{model_name}.keras", overwrite=True)
        with open(f"results/{model_name}-history.yaml", "w", encoding="utf-8") as history_file:
            history_file.write(yaml.dump(history))

        for test_file in test:
            print(f"Testing {test_file} => results/{model_name}-{os.path.basename(test_file)}")
            # apply(model, test_file, f"results/{model_name}-{os.path.basename(test_file)}")

    except Exception as e:
        print(f"Failed to train model {model_name}: {e}")
        raise e


# for model_name in MODELS:
#    model = MODELS[model_name]()
#    try:
#        for n, i in enumerate(list(glob.glob("clean-test/*.png"))):
#            apply(model, i, f"test/{model_name}-{n}.png")
#    except Exception as e:
#        print(f"Failed to apply model {model_name}: {e}")


def run_model(name, max_):
    status = get_status(name)

    filenames = status["files"]

    if status["index"] < len(filenames) and status["index"] < max_:
        files = filenames[status["index"] : status["index"] + NUMBER_OF_IMAGES]
        print("=" * 18)
        print(f"Epoch {status['epoch']} {status['index']}/{len(filenames)}")
        print("=" * 18)

        cmd = [sys.argv[0], f"--name={name}"]
        cmd += [f"--file={filename}" for filename in files]
        cmd += [f"--test={filename}" for filename in status["test_files"]]
        subprocess.run(cmd, check=True)

        status["index"] += NUMBER_OF_IMAGES
        with open(f"results/{name}-status.yaml", "w", encoding="utf-8") as status_file:
            status_file.write(yaml.dump(status))


def _main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--name",
        # default=f"model_{IMAGE_SIZE}_YUV_32_64",
        # default=f"model_{IMAGE_SIZE}_YUV_64_128_256",
        default=list(MODELS.keys())[0],
        help="The name of the model, " + ", ".join(MODELS.keys()),
    )
    parser.add_argument("--file", action="append", help="The files to process")
    parser.add_argument("--test", action="append", help="The test files")
    parser.add_argument("--apply", action="store_true", help="Generate the test files")
    parser.add_argument("--models", action="store_true", help="List the models")
    parser.add_argument("--all", action="store_true", help="run on all models")
    parser.add_argument("--ln", action="store_true", help="create link from grouped directory")
    parser.add_argument(
        "--generate-augmentation-image", action="store_true", help="Generate the data augmentation images"
    )

    args = parser.parse_args()

    if args.ln:
        for model in MODELS.keys():
            for filename in glob.glob(f"results/{model}*"):
                suffix = os.path.basename(filename)[len(model) :]
                if suffix.startswith("."):
                    dir = suffix[1:]
                    suffix = f"{model}{suffix}"
                elif suffix.startswith("-"):
                    suffix_split = suffix[1:].split(".")
                    dir = suffix_split[0]
                    suffix = f"{model}.{suffix_split[1]}"
                else:
                    suffix_split = suffix.split(".")
                    dir = suffix_split[0]
                    suffix = f"{model}.{suffix_split[1]}"
                if not os.path.exists(f"results/{dir}"):
                    os.makedirs(f"results/{dir}")
                if os.path.exists(f"results/{dir}/{suffix}"):
                    os.remove(f"results/{dir}/{suffix}")
                print(f"results/{dir}/{suffix}", f"../{os.path.basename(filename)}")
                os.symlink(f"../{os.path.basename(filename)}", f"results/{dir}/{suffix}")
        return

    if args.file:
        train_many(args.name, args.file, args.test, args.generate_augmentation_image)
        return
    if args.models:
        for model in MODELS.keys():
            print(model)
        return

    if args.apply:
        from clean_document.apply import apply

        if os.path.exists(f"results/{args.name}.keras"):
            model = keras.models.load_model(f"results/{args.name}.keras")
        else:
            model = MODELS[args.name]()
        for test_file in get_status(args.name)["test_files"]:
            print(f"Testing {test_file} => results/{args.name}-{os.path.basename(test_file)}")
            apply(
                model,
                test_file,
                f"results/{args.name}-{os.path.basename(test_file)}",
                segmentation=True,
                square_size=32,
            )
        exit()

    max_ = 0
    while True:
        if args.all:
            for model in MODELS.keys():
                run_model(model, max_)
        else:
            assert args.name is not None
            run_model(args.name, 999999)
        max_ += NUMBER_OF_IMAGES


def get_status(name):
    if os.path.exists(f"results/{name}-status.yaml"):
        with open(f"results/{name}-status.yaml", encoding="utf-8") as status_file:
            return yaml.load(status_file.read(), Loader=yaml.SafeLoader)
    else:
        files = list(glob.glob("clean-data/*.png"))
        random.shuffle(files)
        return {
            "files": files,
            "index": 0,
            "epoch": 0,
            "test_files": list(glob.glob("clean-test/*.png")),
        }


if __name__ == "__main__":
    _main()
