#!/usr/bin/env python3

import argparse
import glob

import keras.saving
import matplotlib.pyplot as plt
import numpy as np
from keras.preprocessing import image

from clean_document.utils import train_val_split

IMAGE_DIMENSION = 256


def load_image(path):
    image_list = np.zeros((len(path), IMAGE_DIMENSION, IMAGE_DIMENSION, 3))
    for i, fig in enumerate(path):
        img = image.load_img(
            fig,
            target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION, 3),
        )
        x = image.img_to_array(img).astype("float32")
        image_list[i] = x

    return image_list


def train_model(name, model, x_train, y_train, x_val, y_val, epochs, batch_size=20):
    history = model.fit(
        x_train,
        y_train,
        batch_size=batch_size,
        epochs=epochs,
        validation_data=(x_val, y_val),
    )
    plt.plot(history.history["loss"])
    plt.plot(history.history["val_loss"])
    plt.title("Model loss")
    plt.ylabel("Loss")
    plt.xlabel("Epoch")
    plt.legend(["Train", "Test"], loc="upper left")
    # save plot to file
    plt.savefig(f"{name}.png")


def train(model_name: str):
    TRAIN_IMAGES = glob.glob("augmented_data/train-x/*.png")
    CLEAN_IMAGES = glob.glob("augmented_data/train-y/*.png")

    x_train = load_image(TRAIN_IMAGES)
    y_train = load_image(CLEAN_IMAGES)
    print(x_train.shape, y_train.shape)

    x_train, y_train, x_val, y_val = train_val_split(x_train, y_train)
    print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)

    model = keras.saving.load_model(f"{model_name}.keras")
    model.summary()
    try:
        train_model(model_name, model, x_train, y_train, x_val, y_val, epochs=5, batch_size=20)
        # Save the model
        model.save(f"{model_name}-finalized.keras", overwrite=True)
    except Exception as e:
        print(f"Failed to train model {model_name}: {e}")
        raise e


def _main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument("--name", default="model_64_128")
    args = parser.parse_args()

    # data_augmentation_clean_()
    # data_augmentation_()
    train(args.name)


if __name__ == "__main__":
    _main()
