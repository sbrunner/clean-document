#!/usr/bin/env python3

# TODO
# electricite
# tranche Dumnica

import argparse
import glob
import os.path
import random
import subprocess
import sys
from collections.abc import Callable

import cv2
import keras.saving
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
import yaml
from keras.layers import Conv2D, Conv2DTranspose, Dropout, Input, MaxPooling2D, UpSampling2D, concatenate
from keras.models import Model

from clean_document.apply import apply
from clean_document.utils import data_augmentation_image

NUMBER_OF_IMAGES = 5
IMAGE_DIMENSION = 256

# TODO
# - Document Renovate usage in c2cgiutils wiki
# - Add zero padding in apply to fit convolutioner


class UNetModel:
    def __init__(self, nb_layers, start_neurons):
        self.nb_layers = nb_layers
        self.start_neurons = start_neurons

    def __call__(self) -> Model:
        start_neurons = self.start_neurons

        input_layer = Input(shape=(None, None, 3), dtype=tf.float32, name="image_input")
        input_layer = Input(shape=(None, None, 3), name="image_input")

        output = input_layer
        conv = {}

        # Encoder
        for i in range(a, self.nb_layers + 1):
            output = Conv2D(
                start_neurons * 1, (3, 3), activation="relu", padding="same", name=f"ConvEnc{i}a"
            )(output)
            output = Conv2D(
                start_neurons * 1, (3, 3), activation="relu", padding="same", name=f"ConvEnc{i}b"
            )(output)
            conv[i] = output
            pool = MaxPooling2D((2, 2))(output)
            output = Dropout(0.25)(pool)

        # Middle
        output = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same", name="ConvMiddle1")(
            output
        )
        output = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same", name="ConvMiddle2")(
            output
        )

        # Down
        for i in range(self.nb_layers, 0, -1):
            deconv = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(output)
            output = concatenate([deconv, conv[i]])
            output = Dropout(0.5)(output)
            output = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(output)
            output = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(output)

        output_layer = Conv2D(3, (1, 1), padding="same", activation="sigmoid")(output)

        model = Model(inputs=input_layer, outputs=output_layer)
        model.compile(optimizer="adam", loss="binary_crossentropy")

        return model


class VNetModel:
    def __init__(self, nb_layers, start_neurons):
        self.nb_layers = nb_layers
        self.start_neurons = start_neurons

    def __call__(self) -> Model:
        input_img = Input(shape=(None, None, 3), name="image_input")
        neuron = self.start_neurons
        output = input_img

        # Encoder
        for i in range(self.nb_layers):
            output = Conv2D(neuron, (3, 3), activation="relu", padding="same", name=f"ConvEnc{i}")(output)
            output = MaxPooling2D((2, 2), padding="same", name=f"pool{i}")(output)
            neuron *= 2

        # Decoder
        for i in range(self.nb_layers):
            neuron = int(neuron / 2)
            output = Conv2D(neuron, (3, 3), activation="relu", padding="same", name=f"ConvDec{i}")(output)
            output = UpSampling2D((2, 2), name=f"upsample{i}")(output)

        output = Conv2D(3, (3, 3), activation="sigmoid", padding="same", name="ConvDec")(output)
        model = Model(inputs=input_img, outputs=output)
        model.compile(optimizer="adam", loss="binary_crossentropy")
        return model


def model_32_64():
    input_img = Input(shape=(None, None, 3), name="image_input")

    # Encoder
    x = Conv2D(32, (3, 3), activation="relu", padding="same", name="Conv1")(input_img)
    x = MaxPooling2D((2, 2), padding="same", name="pool1")(x)
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="Conv2")(x)
    x = MaxPooling2D((2, 2), padding="same", name="pool2")(x)

    # Decoder
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="Conv3")(x)
    x = UpSampling2D((2, 2), name="upsample1")(x)
    x = Conv2D(32, (3, 3), activation="relu", padding="same", name="Conv4")(x)
    x = UpSampling2D((2, 2), name="upsample2")(x)
    x = Conv2D(3, (3, 3), activation="sigmoid", padding="same", name="Conv5")(x)

    # Model
    autoencoder = Model(inputs=input_img, outputs=x)
    autoencoder.compile(optimizer="adam", loss="binary_crossentropy")

    return autoencoder


def model_64_128() -> Model:
    input_img = Input(shape=(None, None, 3), name="image_input")

    # Encoder
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="ConvEnc1")(input_img)
    x = MaxPooling2D((2, 2), padding="same", name="pool1")(x)
    x = Conv2D(128, (3, 3), activation="relu", padding="same", name="ConvEnc2")(x)
    x = MaxPooling2D((2, 2), padding="same", name="pool2")(x)

    # Decoder
    x = Conv2D(128, (3, 3), activation="relu", padding="same", name="ConvDec1")(x)
    x = UpSampling2D((2, 2), name="upsample1")(x)
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="ConvDec2")(x)
    x = UpSampling2D((2, 2), name="upsample2")(x)
    x = Conv2D(3, (3, 3), activation="sigmoid", padding="same", name="ConvDec3")(x)

    # Model
    autoencoder = Model(inputs=input_img, outputs=x)
    autoencoder.compile(optimizer="adam", loss="binary_crossentropy")

    return autoencoder


def model_64_128_256() -> Model:
    input_img = Input(shape=(None, None, 3), name="image_input")

    # Encoder
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="ConvEnc1")(input_img)
    x = MaxPooling2D((2, 2), padding="same", name="pool1")(x)
    x = Conv2D(128, (3, 3), activation="relu", padding="same", name="ConvEnc2")(x)
    x = MaxPooling2D((2, 2), padding="same", name="pool2")(x)
    x = Conv2D(256, (3, 3), activation="relu", padding="same", name="ConvEnc3")(x)
    x = MaxPooling2D((2, 2), padding="same", name="pool3")(x)

    # Decoder
    x = Conv2D(256, (3, 3), activation="relu", padding="same", name="ConvDec1")(x)
    x = UpSampling2D((2, 2), name="upsample1")(x)
    x = Conv2D(128, (3, 3), activation="relu", padding="same", name="ConvDec2")(x)
    x = UpSampling2D((2, 2), name="upsample2")(x)
    x = Conv2D(64, (3, 3), activation="relu", padding="same", name="ConvDec3")(x)
    x = UpSampling2D((2, 2), name="upsample3")(x)
    x = Conv2D(3, (3, 3), activation="sigmoid", padding="same", name="ConvDec4")(x)

    # Model
    autoencoder = Model(inputs=input_img, outputs=x)
    autoencoder.compile(optimizer="adam", loss="binary_crossentropy")

    return autoencoder


MODELS: dict[str, Callable[[], Model]] = {
    # f"model_{IMAGE_DIMENSION}_YUV_32_64": model_32_64,
    # f"model_{IMAGE_DIMENSION}_YUV_64_128": model_64_128,
    # f"model_{IMAGE_DIMENSION}_YUV_64_128_256": model_64_128_256,
    # f"model_{IMAGE_DIMENSION}_YUV_u_net_16": UNetModel(4, 16),
    # f"model_{IMAGE_DIMENSION}_YUV_u_net_32": UNetModel(4, 32),
    # f"model_{IMAGE_DIMENSION}_YUV_u_net_64": UNetModel(4, 64),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_2_32": VNetModel(2, 32),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_2_64": VNetModel(2, 64),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_3_8": VNetModel(3, 8),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_3_16": VNetModel(3, 16),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_3_32": VNetModel(3, 32),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_3_64": VNetModel(3, 64),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_3_128": VNetModel(3, 128),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_4": VNetModel(4, 4),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_8": VNetModel(4, 8),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_16": VNetModel(4, 16),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_32": VNetModel(4, 32),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_64": VNetModel(4, 64),
    f"model_{IMAGE_DIMENSION}_YUV_v_net_4_128": VNetModel(4, 128),
}


# Generator that returns the images
class Images:
    def __init__(self, filenames: list[str]):
        self.filenames = filenames

    def __call__(self):
        for filename in self.filenames:
            images = data_augmentation_image(filename, IMAGE_DIMENSION, save=False)
            for image in images:
                image = image.astype("float32") / 255.0
                image = np.expand_dims(image, axis=0)
                yield image, image


def train_many(model_name: str, filenames: list[str], test: list[str]) -> None:
    if os.path.exists(f"results/{model_name}.keras"):
        model = keras.saving.load_model(f"results/{model_name}.keras")
    else:
        model = MODELS[model_name]()
    if not os.path.exists(f"results/{model_name}.summary"):
        with open(f"results/{model_name}.summary", "w", encoding="utf-8") as summary_file:
            model.summary(print_fn=lambda x: summary_file.write(x + "\n"))

    # create a tf.data.Dataset.from_generator that returns to numpy array od shape (255, 255, 3
    train = tf.data.Dataset.from_generator(
        Images(filenames),
        output_signature=(
            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
        ),
    )
    val = tf.data.Dataset.from_generator(
        Images(test),
        output_signature=(
            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
            tf.TensorSpec(shape=(None, None, None, 3), dtype=tf.float32),
        ),
    )

    try:
        if os.path.exists(f"results/{model_name}-history.yaml"):
            with open(f"results/{model_name}-history.yaml", encoding="utf-8") as history_file:
                history = yaml.load(history_file.read(), Loader=yaml.SafeLoader)
        else:
            history = {
                "loss": [],
                "val_loss": [],
            }
        hist = model.fit(
            train,
            validation_data=val,
            batch_size=1000,
        )
        history.setdefault("loss", []).append(hist.history["loss"])
        history.setdefault("val_loss", []).append(hist.history["val_loss"])

        plt.plot(history["loss"])
        plt.plot(history["val_loss"])
        plt.title("Model loss")
        plt.ylabel("Loss")
        plt.legend(["Train", "Test"], loc="upper left")
        # Save plot to file
        plt.savefig(f"results/{model_name}.png")

        # Save the model
        model.save(f"results/{model_name}.keras", overwrite=True)
        with open(f"results/{model_name}-history.yaml", "w", encoding="utf-8") as history_file:
            history_file.write(yaml.dump(history))

        for test_file in test:
            print(f"Testing {test_file} => results/{model_name}-{os.path.basename(test_file)}")
            apply(model, test_file, f"results/{model_name}-{os.path.basename(test_file)}")

    except Exception as e:
        print(f"Failed to train model {model_name}: {e}")
        raise e


def _main() -> None:
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--name",
        # default=f"model_{IMAGE_DIMENSION}_YUV_32_64",
        # default=f"model_{IMAGE_DIMENSION}_YUV_64_128_256",
        default=list(MODELS.keys())[0],
        help="The name of the model, " + ", ".join(MODELS.keys()),
    )
    parser.add_argument("--file", action="append", help="The files to process")
    parser.add_argument("--test", action="append", help="The test files")
    parser.add_argument("--apply", action="store_true", help="Generate the test files")
    parser.add_argument("--models", action="store_true", help="List the models")
    parser.add_argument("--all", action="store_true", help="run on all models")
    parser.add_argument("--ln", action="store_true", help="create ling from grouped directory")
    parser.add_argument(
        "--generate-augmentation-image", action="store_true", help="Generate the data augmentation images"
    )

    args = parser.parse_args()

    if args.ln:
        for model in MODELS.keys():
            for filename in glob.glob(f"results/{model}*"):
                suffix = os.path.basename(filename)[len(model) :]
                if suffix.startswith("."):
                    dir = suffix[1:]
                    suffix = f"{model}{suffix}"
                elif suffix.startswith("-"):
                    suffix_split = suffix[1:].split(".")
                    dir = suffix_split[0]
                    suffix = f"{model}.{suffix_split[1]}"
                else:
                    suffix_split = suffix.split(".")
                    dir = suffix_split[0]
                    suffix = f"{model}.{suffix_split[1]}"
                if not os.path.exists(f"results/{dir}"):
                    os.makedirs(f"results/{dir}")
                if os.path.exists(f"results/{dir}/{suffix}"):
                    os.remove(f"results/{dir}/{suffix}")
                print(f"results/{dir}/{suffix}", f"../{os.path.basename(filename)}")
                os.symlink(f"../{os.path.basename(filename)}", f"results/{dir}/{suffix}")
        return

    if args.file:
        train_many(args.name, args.file, args.test)
        return
    if args.generate_augmentation_image:
        data_augmentation_image(
            list(glob.glob("clean-data/*.png"))[0], IMAGE_DIMENSION, category="test", save=True
        )
        return
    if args.models:
        for model in MODELS.keys():
            print(model)
        return

    if args.apply:
        if os.path.exists(f"results/{args.name}.keras"):
            model = keras.saving.load_model(f"results/{args.name}.keras")
        else:
            model = MODELS[args.name]()
        for test_file in get_status(args.name)["test_files"]:
            print(f"Testing {test_file} => results/{args.name}-{os.path.basename(test_file)}")
            apply(model, test_file, f"results/{args.name}-{os.path.basename(test_file)}")
        exit()

    max = 0
    while True:
        if args.all:
            for model in MODELS.keys():
                run_model(model, max)
        else:
            assert args.name is not None
            run_model(args.name, 999999)
        max += 5


def get_status(name):
    if os.path.exists(f"results/{name}-status.yaml"):
        with open(f"results/{name}-status.yaml", encoding="utf-8") as status_file:
            return yaml.load(status_file.read(), Loader=yaml.SafeLoader)
    else:
        files = list(glob.glob("clean-data/*.png"))
        random.shuffle(files)
        return {
            "files": files,
            "index": 0,
            "epoch": 0,
            "test_files": list(glob.glob("clean-test/*.png")),
        }


def run_model(name, max):
    status = get_status(name)

    filenames = status["files"]

    if status["index"] < len(filenames) and status["index"] < max:
        files = filenames[status["index"] : status["index"] + NUMBER_OF_IMAGES]
        print("=" * 18)
        print(f"Epoch {status['epoch']} {status['index']}/{len(filenames)}")
        print("=" * 18)

        cmd = [sys.argv[0], f"--name={name}"]
        cmd += [f"--file={filename}" for filename in files]
        cmd += [f"--test={filename}" for filename in status["test_files"]]
        subprocess.run(cmd, check=True)

        status["index"] += NUMBER_OF_IMAGES
        with open(f"results/{name}-status.yaml", "w", encoding="utf-8") as status_file:
            status_file.write(yaml.dump(status))


if __name__ == "__main__":
    _main()
